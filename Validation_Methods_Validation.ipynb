{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This report validates the accuracy of KS test and bootstrapping Sharpe by simulating market alpha series over time. All simulated alpha series follow the same distribution and hence both tests should be able to pick number of inconsistent tests according to significant levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data\n",
    "\n",
    "_BWD_Alpha-MCWTR-BrBetaR3KFast_C2C_W1.csv\n",
    "\n",
    "'2010-01-01':'2018-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import validation\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import matplotlib.pyplot as plt\n",
    "import pyflux as pf\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = [15,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pooldump= r\"\\\\farmnas\\farm2\\Research\\DH_FUNDAMENTAL\\Data\\PHRES-608\\20190802\\_poolDump\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_partitions(partitions, list_num_par):\n",
    "\n",
    "    '''\n",
    "\n",
    "    merge dataframe partitions\n",
    "\n",
    "    Args:\n",
    "\n",
    "        partitions (dict): dict of dataframes\n",
    "        list_num_par (list of int): list of dataframe indexes to merge\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        df (pandas.DataFrame): merged df\n",
    "\n",
    "    '''\n",
    "\n",
    "    df = partitions[0]\n",
    "\n",
    "    for num_par in list_num_par[1:]:\n",
    "\n",
    "        df=df.append(partitions[num_par])\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_CI(series, ci):\n",
    "    \n",
    "    \"\"\"\n",
    "    calculate lower and upper bound at confidence level ci\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    lower_bound=np.percentile(series,  (100-ci)/2)\n",
    "    upper_bound=np.percentile(series,  ci+(100-ci)/2)\n",
    "    \n",
    "    return lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method\n",
    "\n",
    "EW daily alpha across pool is calculated and used as a continue alpha series for resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrapping Daily EW Alpha Series  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation = 10000\n",
    "df_pool = pd.read_csv(dir_pooldump + \"_PI.csv\", index_col = 0)\n",
    "df_1D_Alpha = pd.read_csv(dir_pooldump + \"_BWD_Alpha-MCWTR-BrBetaR3KFast_C2C_W1.csv\", index_col = 0).ix['2010-01-01':'2018-12-31']\n",
    "df_1D_Alpha = df_1D_Alpha[df_pool == 1]\n",
    "df_1D_market_alpha = df_1D_Alpha.mean(axis = 1)\n",
    "\n",
    "partitions=np.array_split(df_1D_market_alpha, num_simulation)\n",
    "\n",
    "list_partitions=list(range(num_simulation))\n",
    "\n",
    "df_simulaiton = pd.DataFrame(index = df_1D_market_alpha.index, columns = list_partitions)\n",
    "\n",
    "for i in range(num_simulation):\n",
    "\n",
    "    df_simulaiton[i] = np.random.choice(df_1D_market_alpha.fillna(0).tolist(), len(df_1D_market_alpha), replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks = pd.DataFrame(index = range(num_simulation), columns = ['ks_pvalue'])\n",
    "\n",
    "for i in range(num_simulation):\n",
    "        \n",
    "    train_ret = df_simulaiton[i].loc['2010-01-01':'2015-12-31']\n",
    "    valid_ret =  df_simulaiton[i].loc['2016-01-01':'2018-12-31']\n",
    "\n",
    "    rvs1 = train_ret.values\n",
    "    rvs2 = valid_ret.values\n",
    "    \n",
    "    _, _pValue = stats.ks_2samp(rvs1, rvs2)\n",
    "    df_ks.loc[i] = float(_pValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 510 simulations out of 10000 have p-value less than 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ks_pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.295090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.516758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.771727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ks_pvalue\n",
       "count  10000.000000\n",
       "mean       0.511600\n",
       "std        0.295090\n",
       "min        0.000172\n",
       "25%        0.260344\n",
       "50%        0.516758\n",
       "75%        0.771727\n",
       "max        0.999830"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ks = df_ks.astype(float)\n",
    "df_ks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ks_pvalue    510\n",
       "dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_ks < 0.05).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Boostrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(df_1D_market_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 5\n",
    "\n",
    "perf_metric_func = lambda df: df.mean(axis=0) / df.std(axis=0)*(252**0.5)\n",
    "\n",
    "df_boostrap_sharpe_val = pd.DataFrame(index=range(num_simulation), columns=['lower_bound_95', 'upper_bound_95',\n",
    "                                                                            'lower_bound_90', 'upper_bound_90',\n",
    "                                                                            'observed_value'])\n",
    "\n",
    "for _simu in range(num_simulation):\n",
    "\n",
    "    train_series = df_simulaiton[_simu].loc['2010-01-01':'2015-12-31']\n",
    "    valid_series = df_simulaiton[_simu].loc['2016-01-01':'2018-12-31']\n",
    "\n",
    "    train_num_partition=int(train_series.shape[0] / partition_size)\n",
    "    valid_num_partition=int(valid_series.shape[0] / partition_size)\n",
    "\n",
    "    partitions=np.array_split(train_series, train_num_partition)\n",
    "\n",
    "    list_partitions=list(range(train_num_partition))\n",
    "\n",
    "    df_sharpe_simulaiton=pd.DataFrame(index=range(100), columns=['measurement'])\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        simulated_valid_partition_num=np.random.choice(list_partitions, valid_num_partition, replace=True)\n",
    "\n",
    "        df_simulated_valid=merge_partitions(partitions, simulated_valid_partition_num)\n",
    "\n",
    "        df_sharpe_simulaiton.ix[i]=perf_metric_func(df_simulated_valid)\n",
    "\n",
    "    lower_bound_95, upper_bound_95 = get_CI(df_sharpe_simulaiton['measurement'], 95)\n",
    "    lower_bound_90, upper_bound_90 = get_CI(df_sharpe_simulaiton['measurement'], 90)\n",
    "    observed_value = perf_metric_func(valid_series)\n",
    "    \n",
    "    temp = [lower_bound_95, upper_bound_95, lower_bound_90, upper_bound_90, observed_value]\n",
    "    df_boostrap_sharpe_val.ix[_simu] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the test rejects 1401 out of 10000 series with 95% CI and rejects 2081 out of 10000 series with 90% CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boostrap_sharpe_val[(df_boostrap_sharpe_val['observed_value'] < df_boostrap_sharpe_val['lower_bound_95']) \n",
    "                      | (df_boostrap_sharpe_val['observed_value'] > df_boostrap_sharpe_val['upper_bound_95'])].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boostrap_sharpe_val[(df_boostrap_sharpe_val['observed_value'] < df_boostrap_sharpe_val['lower_bound_90']) \n",
    "                      |(df_boostrap_sharpe_val['observed_value'] > df_boostrap_sharpe_val['upper_bound_90'])].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result\n",
    "\n",
    "KS is more accurate in this test and boostrapping Sharpe seems to have higher type 1 error than expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "5% p-value in KS test has been selected as cutoff point to validate strategy's performance and boostrapping sharpe is supplimentary test. For strategies that do not pass the tests, discretionary decision can be made to take the strategy to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
